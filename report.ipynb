{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lucaslzl/search_ia_p1/blob/master/Final_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDgcJ3xfSwxh"
   },
   "source": [
    "# **Introduction to Artificial Intelligence - MO416A**\n",
    "**UNIVERSITY OF CAMPINAS**\n",
    "\n",
    "\n",
    "\n",
    "This work was completed by the following members:\n",
    "\n",
    "\n",
    "\n",
    "*   Aissa Hadj - 265189\n",
    "*   Lucas Zanco Ladeira - 188951\n",
    "*   Matheus Ferraroni - 212142\n",
    "*   Maria Vit√≥ria Rodrigues Oliveira - 262884\n",
    "*   Oscar Ciceri - 164786\n",
    "\n",
    "The original code of the project is located on a [repository inside Github](https://github.com/lucaslzl/ga_ia_p2) and the video showing the search strategies working is on [youtube](https://youtube.com). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction\n",
    "\n",
    "The problem that will be tackled in this project is Feature Selection. It comprehends to obtain a subset of the features available in the dataset to improve the model results. By having irrelevant features in the dataset more processing and memory requirements are necessary. To summarize, some pros may be mentioned:\n",
    "- Reduces Overfitting\n",
    "- Improves Accurracy\n",
    "- Reduces Training Time\n",
    "\n",
    "Feature Selection may be done manually or automatically. Some manual techniques comprehend: univariate selection, feature importance, correlation matrix. Univariate selection has the goal to statistically describe the relation between each feature and the target. Feature importance generates a score for each feature to rank them, for instance, Decision Tree algorithms may rank features according to Gini impurity tests. Finally, Correlation Matrix show the correlation between each pair of features so that features with a high correlation may be removed. The literature presents the usage of optimization techniques to automatically find the best, or a quite good, subset of features. Some of the methods available comprehend:\n",
    "- <b>Exaustive search</b>\n",
    "- <b>Simulated Annealing</b>\n",
    "- <b>Transformation Graph</b>\n",
    "- <b>Genetic Algorithms</b>\n",
    "\n",
    "<b>Exaustive Search</b> is not a optimization technique, but it is worth to be mentioned as the computational complexity $O(2^n)$. This technique tries every subset to find the best one. That presents how it is not feasible in most of the cases to use this technique. <b>Simulated Annealing</b> comprehends is a metaheuristic for complex nonlinear optimization problems and is based on the analogy of the simulation of the annealing of solids. The analogy pairs are as follows: feasible solution (state), cost (energy), optimal solution (ground state), local search (rapid quenching), simulated annealing (careful annealing). <b>Transformation Graph</b> is a strategy that utilizes a tree-like structure to generate possible solutions. For instance, first $n$ solutions are generated by removing at each one distinct feature. Then, all solutions are evaluated. Third, the best solution is chosen and $n-1$ are generated by removing each feature yet not removed. That strategy goes on considering a budget. The problem of this strategy is that it requires a lot of memory. <b>Genetic Algorithm</b> is inspired by genetics (DNA) to search through solutions. It may be briefly explained as the following steps: generates a population considering variations of DNA, rank population according to some score, apply mutations and other transformations to the DNA at each generation, it iterates until a stopping rule. The stopping rule may be the quantity of generations or the obtained solution. This is the strategy applied in this work and will be explained deeply in the next sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We developed 2 classes to control the operation of the genetic algorithm. The classes are 'element' and 'GeneticAlgorithm' and they can be seen in https://github.com/lucaslzl/ga_ia_p2/blob/master/GA.py. In this notebook the class 'element' will be examplained, as well as the main methods of the class 'GeneticAlgorithm'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the entire class 'element' is presented. It is possible to see that this class is only responsible for contain the id, the generation, the genome and the score of each element in each generation.\n",
    "\n",
    "Saving this attributes in the same place can be usefull for different approachs during the implementation of the methods used by the genetic algorithm.\n",
    "\n",
    "Altogh it's not imeplement here, it is possible to save the parents of each element and traceback how each element was formed during the evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class element:\n",
    "\n",
    "    def __init__(self, idd, geracao, genome):\n",
    "        self.idd = idd\n",
    "        self.geracao = geracao\n",
    "        self.genome = genome\n",
    "        self.score = None\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"(id=\"+str(self.idd)+\",geracao=\"+str(self.geracao)+\",score=\"+str(self.score)+\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The genetic algorithm implemented is very generic, this means that it can be used easily for different problems. Using this kind of generic implementation direct it's use to override the functions responsible for generate a random genome, mutate and fitness calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method 'create_initial_population' is called once the gentic algorithm is started. This methodo create one element and add it to the pool of this generation till the pool has the size defined. To create the genome the fuction 'random_genome', that was orverride before, is called for each element.\n",
    "\n",
    "In our problem we define the genome as an array of 0's and 1's with the same length of the amount of t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_population(self):\n",
    "    for _ in range(self.population_size):\n",
    "        self.population.append(element(self.elements_created, 0, self.random_genome()))\n",
    "        self.elements_created += 1\n",
    "\n",
    "\n",
    "def random_genome():\n",
    "    return np.random.randint(low=0,high=2,size=len(df.columns),dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(self):\n",
    "\n",
    "    while self.check_stop():\n",
    "        self.calculate_score() \n",
    "        self.population.sort(key=lambda x: x.score, reverse=True) \n",
    "\n",
    "        if self.best_element_total==None or self.population[0].score > self.best_element_total.score: \n",
    "            self.best_element_total = self.population[0]\n",
    "\n",
    "        self.do_log()\n",
    "\n",
    "        if self.cut_half_population: \n",
    "            self.population = self.population[0:len(self.population)//2] \n",
    "\n",
    "        self.new_population()\n",
    "\n",
    "        self.iteration_counter +=1\n",
    "\n",
    "    return self.best_element_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_population(self):\n",
    "\n",
    "    probs = self.get_probs()\n",
    "    newPop = []\n",
    "    best_replicator = int(self.population_size*self.replicate_best)\n",
    "\n",
    "    while len(newPop)<self.population_size-best_replicator:\n",
    "        parents = np.random.choice(self.population,size=2,p=probs) \n",
    "\n",
    "        if parents[0].score<parents[1].score: \n",
    "            parents = parents[::-1] \n",
    "\n",
    "        new_element = element(self.elements_created, self.iteration_counter, self.crossover(parents[0].genome, parents[1].genome))\n",
    "\n",
    "        new_element.genome = self.active_mutate(new_element.genome)\n",
    "        newPop.append(new_element)\n",
    "        self.elements_created += 1\n",
    "\n",
    "    for i in range(best_replicator):\n",
    "        newPop.append(self.population[i])\n",
    "\n",
    "    self.population = newPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(self):\n",
    "    if self.probs_type == 0:\n",
    "        return self.probs_roulette()\n",
    "    elif self.probs_type == 1:\n",
    "        return self.probs_equal()\n",
    "\n",
    "\n",
    "def probs_equal(self):\n",
    "    return [1/len(self.population)]*len(self.population)\n",
    "\n",
    "\n",
    "def probs_roulette(self):\n",
    "    probs = [0]*len(self.population) \n",
    "    for i in range(len(probs)):\n",
    "        probs[i] = self.population[i].score\n",
    "    div = sum(probs)\n",
    "\n",
    "    if div!=0:\n",
    "        for i in range(len(probs)):\n",
    "            probs[i] /= div\n",
    "    else: \n",
    "        probs = self.probs_equal()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stop(self):\n",
    "    if self.stop_criteria_type==0:\n",
    "        return self.stop_criteria_double()\n",
    "    elif self.stop_criteria_type==1:\n",
    "        return self.stop_criteria_iteration()\n",
    "    elif self.stop_criteria_type==2:\n",
    "        return self.stop_criteria_score()\n",
    "\n",
    "def stop_criteria_double(self):\n",
    "    s = self.population[0].score\n",
    "    if s==None:\n",
    "        s = 0\n",
    "    return self.iteration_counter<self.iteration_limit or s>=self.max_possible_score\n",
    "\n",
    "def stop_criteria_iteration(self):\n",
    "    return self.iteration_counter<self.iteration_limit\n",
    "\n",
    "def stop_criteria_score(self):\n",
    "    s = self.population[0].score\n",
    "    if s==None:\n",
    "        s = 0\n",
    "    return s>=self.max_possible_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(self, genA, genB):\n",
    "    if self.crossover_type==0:\n",
    "        return self.crossover_uniform(genA, genB)\n",
    "    elif self.crossover_type==1:\n",
    "        return self.crossover_single_point(genA, genB)\n",
    "    elif self.crossover_type==2:\n",
    "        return self.crossover_two_point(genA, genB)\n",
    "    elif self.crossover_type==3:\n",
    "        return self.crossover_rate_selection(genA, genB)\n",
    "\n",
    "def crossover_rate_selection(self, genA, genB):\n",
    "    new = np.array([],dtype=int)\n",
    "    for i in range(len(genA)):\n",
    "        if np.random.random()<self.crossover_rate:\n",
    "            new = np.append(new, genA[i])\n",
    "        else:\n",
    "            new = np.append(new, genB[i])\n",
    "    return new\n",
    "\n",
    "\n",
    "def crossover_uniform(self, genA, genB):\n",
    "    new = np.array([],dtype=int)\n",
    "    for i in range(len(genA)):\n",
    "        if np.random.random()<0.5:\n",
    "            new = np.append(new, genA[i])\n",
    "        else:\n",
    "            new = np.append(new, genB[i])\n",
    "    return new\n",
    "\n",
    "\n",
    "def crossover_single_point(self, genA, genB):\n",
    "    p = np.random.randint(low=1,high=len(genA)-1) \n",
    "    return np.append(genA[0:p],genB[p:])\n",
    "\n",
    "\n",
    "def crossover_two_point(self, genA, genB):\n",
    "    c1 = c2 = np.random.randint(low=0,high=len(genA)) \n",
    "    while c2==c1: \n",
    "        c2 = np.random.randint(low=0,high=len(genA))\n",
    "\n",
    "    if c1>c2: \n",
    "        c1, c2 = c2,c1\n",
    "\n",
    "    new = np.append(np.append(genA[0:c1],genB[c1:c2]),genA[c2:]) \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(self):\n",
    "    if self.use_threads: \n",
    "\n",
    "        threads_running = []\n",
    "        for e in self.population:\n",
    "            x = threading.Thread(target=self.thread_evaluate, args=(e,))\n",
    "            x.start()\n",
    "            threads_running.append(x)\n",
    "\n",
    "        for i in range(len(threads_running)):\n",
    "            threads_running[i].join()\n",
    "\n",
    "    else: \n",
    "        for e in self.population:\n",
    "            e.score = self.evaluate(e.genome)\n",
    "\n",
    "def thread_evaluate(self, e):\n",
    "    e.score = self.evaluate(e.genome)\n",
    "    \n",
    "\n",
    "def evaluate(genome):\n",
    "    bool_genome = list(map(bool, genome))\n",
    "    return model.evaluate(df.loc[:, bool_genome].copy(), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_mutate(self,gen):\n",
    "    if self.mutation_rate<=0: \n",
    "        return gen\n",
    "    for i in range(len(gen)): \n",
    "        if np.random.random()<self.mutation_rate: \n",
    "            gen = self.mutate1(i, gen) \n",
    "    return gen\n",
    "\n",
    "\n",
    "def mutate1(index, genome):\n",
    "    if genome[index]==0:\n",
    "        genome[index] = 1\n",
    "    else:\n",
    "        genome[index] = 0\n",
    "    return genome\n",
    "\n",
    "\n",
    "def mutate2(index, genome):\n",
    "    aux = []\n",
    "    for i in range(len(genome)):\n",
    "        if i <= index:\n",
    "            aux.append(genome[i])\n",
    "        else:\n",
    "            aux.insert(0, genome[i])\n",
    "    genome = aux\n",
    "    if genome[index]==0:\n",
    "        genome[index] = 1\n",
    "    else:\n",
    "        genome[index] = 0\n",
    "    return genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TzNJDNdBSiXy",
    "Xe1hkEvOZgT8",
    "Hc-yvZ4qbkgh"
   ],
   "include_colab_link": true,
   "name": "Final Report.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
